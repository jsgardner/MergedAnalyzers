{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from IPython.display import FileLink, FileLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 image has 16x16 pixels = 256 pixels\n",
    "pixels = [\"pixel_{0}\".format(i) for i in range(36)]\n",
    "\n",
    "def to_image(df):\n",
    "    return  np.expand_dims(np.expand_dims(df[pixels], axis=-1).reshape(-1,6,6), axis=-1)\n",
    "\n",
    "\n",
    "#store_train = pandas.HDFStore(\"SNG_p10_pixelTrain.h5\")\n",
    "store_train = pandas.HDFStore(\"pixelTrain.h5\")\n",
    "#store_train = pandas.HDFStore(\"pixelTrain.h5\")\n",
    "\n",
    "df_train = store_train.select(\"df\",stop=-1)\n",
    "df_train = df_train[(df_train[\"GenDeltaR\"]<0.1) & (df_train[\"nUniqueSimTracksInSharedHit\"]>-1)]\n",
    "images_train = to_image(df_train)\n",
    "\n",
    "store_test = pandas.HDFStore(\"pixelTrain30k.h5\")\n",
    "\n",
    "df_test = store_test.select(\"df\",stop=-1)\n",
    "df_test = df_test[(df_test[\"GenDeltaR\"]<0.1) & (df_test[\"nUniqueSimTracksInSharedHit\"]>-1)]#print(df_test)\n",
    "images_test = to_image(df_test)\n",
    "\n",
    "#comb = pandas.concat([df_train,df_test])\n",
    "\n",
    "#df_train=comb.sample(frac=0.6)\n",
    "#df_test=comb.drop(df_train.index)\n",
    "\n",
    "#df_train = df_train[(df_train[\"GenDeltaR\"]<0.1) & (df_train[\"nUniqueSimTracksInSharedHit\"]>-1)]\n",
    "\n",
    "# Make all test, train data merged hit\n",
    "df_test = df_test[(df_test[\"isSharedHit\"]>0)]\n",
    "df_train = df_train[(df_train[\"isSharedHit\"]>0)]\n",
    "\n",
    "#images_train = to_image(df_train)\n",
    "#images_test = to_image(df_test)\n",
    "\n",
    "\n",
    "#print(df_train.iloc[[28946]])\n",
    "#print(df_train)\n",
    "#print df_train\n",
    "#print sum(df_train[\"isSharedHit\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 42)\n",
      "(313, 42)\n"
     ]
    }
   ],
   "source": [
    "store_train = pandas.HDFStore(\"pixelTrain.h5\")\n",
    "\n",
    "df_train = store_train.select(\"df\",stop=-1)\n",
    "df_train = df_train[(df_train[\"GenDeltaR\"]<0.1) & (df_train[\"nUniqueSimTracksInSharedHit\"]>-1)]\n",
    "\n",
    "store_test = pandas.HDFStore(\"pixelTrain30k.h5\")\n",
    "\n",
    "df_test = store_test.select(\"df\",stop=-1)\n",
    "df_test = df_test[(df_test[\"GenDeltaR\"]<0.1) & (df_test[\"nUniqueSimTracksInSharedHit\"]>-1)]#print(df_test)\n",
    "\n",
    "print df_test.shape\n",
    "print df_train.shape\n",
    "\n",
    "# Remove overlap between train and test data\n",
    "df_combined = pandas.concat([df_test, df_train]).drop_duplicates(keep=False)\n",
    "df_combined.shape\n",
    "\n",
    "\n",
    "# New combined files\n",
    "df_train=df_combined.sample(frac=0.6)\n",
    "df_test=df_combined.drop(df_train.index)\n",
    "\n",
    "# Make all test, train data merged hit\n",
    "df_test = df_test[(df_test[\"isSharedHit\"]>0)]\n",
    "df_train = df_train[(df_train[\"isSharedHit\"]>0)]\n",
    "\n",
    "df_train = df_train[(df_train[\"GenDeltaR\"]<0.1) & (df_train[\"nUniqueSimTracksInSharedHit\"]>-1)]\n",
    "\n",
    "\n",
    "images_train = to_image(df_train)\n",
    "images_test = to_image(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 42)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augment_train = df_train.iloc[0:1]\n",
    "augment_train = to_image(df_augment_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "datagen.fit(images_train, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isMergedHit</th>\n",
       "      <th>isSharedHit</th>\n",
       "      <th>trackPt</th>\n",
       "      <th>trackEta</th>\n",
       "      <th>trackPhi</th>\n",
       "      <th>nUniqueSimTracksInSharedHit</th>\n",
       "      <th>GenDeltaR</th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_26</th>\n",
       "      <th>pixel_27</th>\n",
       "      <th>pixel_28</th>\n",
       "      <th>pixel_29</th>\n",
       "      <th>pixel_30</th>\n",
       "      <th>pixel_31</th>\n",
       "      <th>pixel_32</th>\n",
       "      <th>pixel_33</th>\n",
       "      <th>pixel_34</th>\n",
       "      <th>pixel_35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.330709</td>\n",
       "      <td>-2.043563</td>\n",
       "      <td>1.330709</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.043240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083277</td>\n",
       "      <td>0.139740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04586</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.927646</td>\n",
       "      <td>-2.203123</td>\n",
       "      <td>1.927646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403630</td>\n",
       "      <td>0.056244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.657765</td>\n",
       "      <td>-1.873906</td>\n",
       "      <td>4.657765</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254677</td>\n",
       "      <td>0.101919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.573482</td>\n",
       "      <td>-0.220184</td>\n",
       "      <td>13.573482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.924295</td>\n",
       "      <td>-2.205955</td>\n",
       "      <td>1.924295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072539</td>\n",
       "      <td>0.114365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     isMergedHit  isSharedHit    trackPt  trackEta   trackPhi  \\\n",
       "69             1            1   1.330709 -2.043563   1.330709   \n",
       "92             0            1   1.927646 -2.203123   1.927646   \n",
       "119            1            1   4.657765 -1.873906   4.657765   \n",
       "228            0            1  13.573482 -0.220184  13.573482   \n",
       "229            0            1   1.924295 -2.205955   1.924295   \n",
       "\n",
       "     nUniqueSimTracksInSharedHit  GenDeltaR  pixel_0  pixel_1   pixel_2  ...  \\\n",
       "69                           2.0   0.043240      0.0      0.0  0.087983  ...   \n",
       "92                           1.0   0.016287      0.0      0.0  0.000000  ...   \n",
       "119                          2.0   0.005257      0.0      0.0  0.000000  ...   \n",
       "228                          1.0   0.003009      0.0      0.0  0.000000  ...   \n",
       "229                          1.0   0.020649      0.0      0.0  0.000000  ...   \n",
       "\n",
       "     pixel_26  pixel_27  pixel_28  pixel_29  pixel_30  pixel_31  pixel_32  \\\n",
       "69   0.083277  0.139740  0.000000       0.0       0.0       0.0   0.04586   \n",
       "92   0.000000  0.403630  0.056244       0.0       0.0       0.0   0.00000   \n",
       "119  0.254677  0.101919  0.000000       0.0       0.0       0.0   0.00000   \n",
       "228  0.000000  0.000000  0.000000       0.0       0.0       0.0   0.00000   \n",
       "229  0.072539  0.114365  0.000000       0.0       0.0       0.0   0.00000   \n",
       "\n",
       "     pixel_33  pixel_34  pixel_35  \n",
       "69   0.090908       0.0       0.0  \n",
       "92   0.000000       0.0       0.0  \n",
       "119  0.000000       0.0       0.0  \n",
       "228  0.000000       0.0       0.0  \n",
       "229  0.000000       0.0       0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding isMergedHit column \n",
    "\n",
    "merged_hit = df_train[\"nUniqueSimTracksInSharedHit\"]>1\n",
    "merged_int = merged_hit.astype(int)\n",
    "df_train.insert(0, \"isMergedHit\", merged_int, True)\n",
    "\n",
    "#df_train.head()\n",
    "\n",
    "merged_hit_test = df_test[\"nUniqueSimTracksInSharedHit\"]>1\n",
    "merged_int_test = merged_hit_test.astype(int)\n",
    "df_test.insert(0, \"isMergedHit\", merged_int_test, True)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69     1\n",
      "92     1\n",
      "119    1\n",
      "228    1\n",
      "229    1\n",
      "Name: isSharedHit, dtype: int32\n",
      "1668    1\n",
      "7480    1\n",
      "5655    1\n",
      "7993    1\n",
      "433     1\n",
      "Name: isSharedHit, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Check that all are merged hits i.e. isSharedHit=1\n",
    "print df_test['isSharedHit'].head()\n",
    "print df_train['isSharedHit'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113, 43)\n",
      "(174, 43)\n"
     ]
    }
   ],
   "source": [
    "print df_test.shape\n",
    "print df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide as model inputs either a single array or a list of arrays. You passed: x=<keras_preprocessing.image.numpy_array_iterator.NumpyArrayIterator object at 0x7fed1d258b90>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-5d99183e4683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nUniqueSimTracksInSharedHit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# validation fraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_96/x86_64-centos7-gcc8-opt/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_96/x86_64-centos7-gcc8-opt/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    668\u001b[0m                                      \u001b[0;34m'either a single '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                                      \u001b[0;34m'array or a list of arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m                                      'You passed: x=' + str(x))\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mall_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide as model inputs either a single array or a list of arrays. You passed: x=<keras_preprocessing.image.numpy_array_iterator.NumpyArrayIterator object at 0x7fed1d258b90>"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Activation\n",
    "# Define the network\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(4,4), padding='same', activation='relu'))\n",
    "#model.add(keras.layers.Conv2D(16, kernel_size=(4,4), padding='same', activation='relu'))\n",
    "#model.add(keras.layers.Conv2D(16, kernel_size=(2,2), padding='same', activation='relu'))\n",
    "#model.add(keras.layers.Conv2D(16, kernel_size=(1,1), padding='same', activation='relu'))\n",
    "# max pooling 2D\n",
    "#model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same', data_format=\"channels_last\"))\n",
    "model.add(keras.layers.Flatten(input_shape=(6,6,1),data_format = \"channels_last\"))\n",
    "#model.add(keras.layers.Dense(200, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "# dropout 10%\n",
    "model.add(Dropout(0.1))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "#print(model.summary())\n",
    "\n",
    "# Train the network\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adadelta(), metrics = [\"accuracy\"])\n",
    "model.summary\n",
    "model.fit(datagen.flow(images_train, keras.utils.to_categorical(df_train[\"nUniqueSimTracksInSharedHit\"]>1)), epochs=30) # validation fraction\n",
    "print(model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store_test = pandas.HDFStore(\"pixelTrain30k.h5\")\n",
    "\n",
    "#df_test = store_test.select(\"df\",stop=-1)\n",
    "##pixels\n",
    "#df_test[pixels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Evaluate performance on independent sample\n",
    "# DO NOT CHANGE BELOW!\n",
    "\n",
    "# Prepare input\n",
    "#store_test = pandas.HDFStore(\"SNG_p10_pixelTrain.h5\")\n",
    "\n",
    "\n",
    "#store_test = pandas.HDFStore(\"pixelTest_v3.h5\")\n",
    "#store_test = pandas.HDFStore(\"pixelTrain30k.h5\")\n",
    "\n",
    "#df_test = store_test.select(\"df\",stop=-1)\n",
    "#df_test = df_test[(df_test[\"GenDeltaR\"]<0.1) & (df_test[\"nUniqueSimTracksInSharedHit\"]>-1)]#print(df_test)\n",
    "#images_test = to_image(df_test)\n",
    "#images_test = pandas.read_hdf(\"pixelTrain.h5\")\n",
    "#images_test = images_train\n",
    "#df_test = df_train\n",
    "\n",
    "# Run DNN\n",
    "print(\"Running on full test sample. This may take a moment.\")\n",
    "ret = model.predict(images_test)\n",
    "np.save(\"result.npy\",ret[:,1])\n",
    "print(ret)\n",
    "#print ret\n",
    "#print df_test[\"isSharedHit\"]\n",
    "#keras.utils.to_categorical(df_test[\"isSharedHit\"])\n",
    "#print len(keras.utils.to_categorical(df_test[\"isSharedHit\"]))\n",
    "#print keras.utils.to_categorical(df_train[\"isSharedHit\"],dtype='int32').sum()\n",
    "#print len(keras.utils.to_categorical(df_train[\"isSharedHit\"])),keras.utils.to_categorical(df_train[\"isSharedHit\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "#fpr_keras, tpr_keras, thresholds_keras = roc_curve(keras.utils.to_categorical(df_test[\"isSharedHit\"])[:,1], ret[:,1])\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(keras.utils.to_categorical(df_test[\"nUniqueSimTracksInSharedHit\"]>1)[:,1], ret[:,1])\n",
    "\n",
    "print fpr_keras,tpr_keras\n",
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "print auc_keras\n",
    "print np.isnan(fpr_keras).all()\n",
    "print len(fpr_keras),len(tpr_keras)\n",
    "np.save(\"fpr_keras.npy\",fpr_keras)\n",
    "np.save(\"tpr_keras.npy\",tpr_keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fpr_keras = np.load(\"fpr_keras.npy\")\n",
    "tpr_keras = np.load(\"tpr_keras.npy\")\n",
    "#print fpr_keras[2300]\n",
    "auc = np.trapz(tpr_keras,fpr_keras)\n",
    "print auc\n",
    "#auc_keras = 0.623416233325797\n",
    "#auc_keras = 0.665570454761781\n",
    "#print test\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "#plt.figure(figsize=(200, 200))\n",
    "#plt.plot([0, 1], [0, 1], label='test')\n",
    "#plt.plot([1,2,3],[5,6,7], label = 'test')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc))\n",
    "#plt.plot(fpr_keras, tpr_keras, label='test')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (area = {:.3f})'.format(auc))\n",
    "#plt.legend(loc='best')\n",
    "plt.savefig(\"ROC.png\")\n",
    "plt.savefig(\"ROC.pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check: no overlap between train and test\n",
    "pandas.merge(df_train, df_test, on=[x for x in df_train.columns], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[(df_test[\"nUniqueSimTracksInSharedHit\"]>-1) & (df_test[\"GenDeltaR\"]<0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"shared hits with at least 2 sim tracks:\"\n",
    "print float(sum(df_train[\"nUniqueSimTracksInSharedHit\"]>1))/len(df_train[\"nUniqueSimTracksInSharedHit\"])\n",
    "plt.hist(df_train[\"nUniqueSimTracksInSharedHit\"],histtype=\"step\",bins=6,range=(-0.5,5.5))\n",
    "plt.title(\"nUniqueSimTracksInSharedHit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_train[\"nUniqueSimTracksInSharedHit\"]>-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "82.0/30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print float(sum(df_train[\"nUniqueSimTracksInSharedHit\"]>1))/len(df_train[\"nUniqueSimTracksInSharedHit\"])\n",
    "plt.hist(df_train[\"nUniqueSimTracksInSharedHit\"]>1,histtype=\"step\",bins=2,range=(-0.5,1.5))\n",
    "plt.title(\"Distribution of Hits in Training Data\")\n",
    "plt.xticks([0,1],(\"Not Merged\",\"Merged\"))\n",
    "plt.savefig(\"merged_dist.png\")\n",
    "plt.savefig(\"merged_dist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating signal and background for train and test data\n",
    "signal = ret[df_test[\"isMergedHit\"]==1]\n",
    "background = ret[df_test[\"isMergedHit\"]==0]\n",
    "\n",
    "signal_plt = signal[:,1]\n",
    "background_plt = background[:,1]\n",
    "\n",
    "ret_train = model.predict(images_train)\n",
    "\n",
    "signal_train = ret_train[df_train[\"isMergedHit\"]==1]\n",
    "background_train = ret_train[df_train[\"isMergedHit\"]==0]\n",
    "signal_train_plt = signal_train[:,1]\n",
    "background_train_plt = background_train[:,1]\n",
    "\n",
    "Y_back_hist = np.histogram(background_train_plt)[0]\n",
    "X_back_hist = np.histogram(background_train_plt)[1]\n",
    "\n",
    "Y_sig_hist = np.histogram(signal_train_plt)[0]\n",
    "X_sig_hist = np.histogram(signal_train_plt)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Signal and background plot\n",
    "plt.hist(signal_plt, alpha = 0.5, color = 'b', label = 'Signal (test)', range = (0,1), align = 'left')\n",
    "plt.hist(background_plt, color = 'r', alpha = 0.5, label = 'Background (test)', range = (0,1))\n",
    "plt.scatter(X_back_hist[0:10], Y_back_hist, label='Background (train)', color ='r')\n",
    "plt.scatter(X_sig_hist[0:10], Y_sig_hist, label='Signal (train)', color='b')\n",
    "plt.legend(loc='best')\n",
    "plt.title('CNN Signal and Background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(signal_train_plt, align = 'right')\n",
    "plt.scatter([0.1782944 , 0.26801087, 0.35772735, 0.44744383,\n",
    "        0.5371603 , 0.62687678, 0.71659326, 0.80630973, 0.89602621,\n",
    "        0.98574269], [ 3.,  2.,  1.,  2.,  2.,  1.,  8., 14., 17., 42.], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print signal_plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df_test.shape\n",
    "print df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
